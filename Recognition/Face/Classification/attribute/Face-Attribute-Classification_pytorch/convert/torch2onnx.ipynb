{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab7b605-166d-407d-a376-76da057ecb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47ef60b-09b1-4829-ad24-7b1580ddf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import build_model\n",
    "from src.get_config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574af663-f26f-40b0-b554-0c9a5a271935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(rgb_img,mean_list=[0.485, 0.456, 0.406],std_list=[0.229, 0.224, 0.225]):\n",
    "    MEAN = 255 * np.array(mean_list)\n",
    "    STD = 255 * np.array(std_list)\n",
    "    rgb_img = rgb_img.transpose(-1, 0, 1)\n",
    "    norm_img = (rgb_img - MEAN[:, None, None]) / STD[:, None, None]\n",
    "    \n",
    "    return norm_img\n",
    "\n",
    "def preprocessing(aimg,mean_list=[0.485, 0.456, 0.406],std_list=[0.229, 0.224, 0.225]):\n",
    "    input_img = normalization(aimg,mean_list,std_list) # aimg is RGB\n",
    "    input_img = torch.tensor(np.expand_dims(input_img,0).astype(np.float32))\n",
    "    \n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d24b038e-27e4-4d0b-856f-ca31deb40f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"configs/efficientNet_B0_celebA.py\"\n",
    "model_path = \"./save_model_224/best_epoch28.pth\"\n",
    "\n",
    "cfg_path = \"configs/efficientNet_B0_celebA_add.py\"\n",
    "model_path = \"./save_model_add224/best_epoch30.pth\"\n",
    "\n",
    "cfg_path = \"configs/efficientNet_B0_celebA_crop.py\"\n",
    "model_path = \"./save_model_crop224/best_epoch17.pth\"\n",
    "\n",
    "cfg = get_config(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953b0ae1-c913-4b6d-aa8d-12dc97db11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg.network,cfg.num_classes,'',False)\n",
    "\n",
    "load_weight = torch.load(model_path)\n",
    "new_state_dict = OrderedDict()\n",
    "for n, v in load_weight.items():\n",
    "    name = n.replace(\"module.\",\"\") \n",
    "    new_state_dict[name] = v\n",
    "    \n",
    "model.load_state_dict(new_state_dict)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5187aee9-3276-42e8-b0d3-219a830c7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.randint(0, 255, size=(224, 224, 3), dtype=np.uint8)\n",
    "img = preprocessing(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0a7dce6-27a5-4350-b8b5-9a6b72b868a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "output_path = \"./save_model_crop224/efficientNetB0_celebA_crop224.onnx\"\n",
    "opset=12\n",
    "torch.onnx.export(model, img, output_path, keep_initializers_as_inputs=False, verbose=False, opset_version=opset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e2c269f-db43-42cf-801c-c209765e6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify\n",
    "\n",
    "import onnxsim\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(output_path)\n",
    "graph = model.graph\n",
    "graph.input[0].type.tensor_type.shape.dim[0].dim_param = 'None'\n",
    "\n",
    "model, check = onnxsim.simplify(model, input_shapes={\"input.1\":(1, 3, 224, 224)})\n",
    "assert check, \"Simplified ONNX model could not be validated\"\n",
    "onnx.save(model, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306e201-1fc7-4c60-ad18-2d1e00f2f99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
