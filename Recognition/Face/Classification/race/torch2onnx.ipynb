{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "import onnxsim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backbones.linear import ArcfaceLinear_mbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onnx(net, path_module, output, opset=12, simplify=False):\n",
    "    assert isinstance(net, torch.nn.Module)\n",
    "    img = np.random.randint(0, 255, size=(112, 112, 3), dtype=np.uint8)\n",
    "    img = img.astype(np.float)\n",
    "    img = np.transpose(img,(2, 0, 1))\n",
    "    img = torch.from_numpy(img).unsqueeze(0).float()\n",
    "    img.div_(255).sub_(0.5).div_(0.5)\n",
    "\n",
    "    weight = torch.load(path_module)\n",
    "    \n",
    "    if type(weight)==OrderedDict:\n",
    "        try:\n",
    "            net.load_state_dict(weight)\n",
    "        except:\n",
    "            new_state_dict = OrderedDict()\n",
    "            for n, v in weight.items():\n",
    "                name = n.replace(\"module.\",\"\") \n",
    "                new_state_dict[name] = v\n",
    "            net.load_state_dict(new_state_dict)\n",
    "    else:\n",
    "        net.load_state_dict(weight.module.state_dict())\n",
    "    net.eval()\n",
    "    torch.onnx.export(net, img, output, keep_initializers_as_inputs=False, verbose=False, opset_version=opset)\n",
    "    model = onnx.load(output)\n",
    "    graph = model.graph\n",
    "    graph.input[0].type.tensor_type.shape.dim[0].dim_param = 'None'\n",
    "    if simplify:\n",
    "        model, check = onnxsim.simplify(model, input_shapes={\"input.1\":(1, 3, 112, 112)})\n",
    "        assert check, \"Simplified ONNX model could not be validated\"\n",
    "    onnx.save(model, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = \"./race_FairFace-mbf-arcface-sgd_221209_nf/best.pth\"\n",
    "output = \"./race_FairFace-mbf-arcface-sgd_221209_nf/race-mbf-arcface-sgd_221209_nf.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net='mbf'\n",
    "num_classes=6\n",
    "num_features=512\n",
    "fp16=False\n",
    "\n",
    "backbone_onnx = ArcfaceLinear_mbf(pretrained_path='', net =net, num_class=num_classes, num_features=num_features,freeze=False,fp16=fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_onnx(backbone_onnx, weight, output, simplify=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
