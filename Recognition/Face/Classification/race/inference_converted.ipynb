{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from backbones.linear import ArcfaceLinear_mbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (112, 112))\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ori_img = img.copy()\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = torch.from_numpy(img).unsqueeze(0).float()\n",
    "    img.div_(255).sub_(0.5).div_(0.5)\n",
    "    return img,ori_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"FairFace/aligned_fair/val/1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict={0:'White',1:'Black',2:'Asian',3:'Indian',4:'Others',5:'Others'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian\n"
     ]
    }
   ],
   "source": [
    "#torch\n",
    "net='mbf'\n",
    "model_path = \"race-mbf-arcface-sgd_221209_nf.pth\"\n",
    "backbone = ArcfaceLinear_mbf(pretrained_path='', net =net, num_class=6, num_features=512,freeze=False,fp16=False)\n",
    "load_weight = torch.load(model_path)\n",
    "if type(load_weight)==OrderedDict:\n",
    "    try:\n",
    "        backbone.load_state_dict(load_weight)\n",
    "    except:\n",
    "        new_state_dict = OrderedDict()\n",
    "        for n, v in load_weight.items():\n",
    "            name = n.replace(\"module.\",\"\") \n",
    "            new_state_dict[name] = v\n",
    "        backbone.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    try:\n",
    "        backbone.load_state_dict(load_weight.module.state_dict())\n",
    "    except:\n",
    "        backbone.load_state_dict(load_weight.state_dict())\n",
    "_=backbone.eval()\n",
    "\n",
    "img,ori_img = read_img(img_path)\n",
    "output = backbone(img)\n",
    "\n",
    "p,idx = torch.topk(output,1)\n",
    "p = np.array(p.detach())[0]\n",
    "idx = np.array(idx.detach())[0]\n",
    "pred_name = label_dict[idx[0]]\n",
    "\n",
    "print(pred_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_test.model_zoo.model_common import load_tensorRT, load_onnx, load_openvino,load_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providers: ['CUDAExecutionProvider']\n",
      "Asian\n"
     ]
    }
   ],
   "source": [
    "# onnx\n",
    "model_path = \"race-mbf-arcface-sgd_221209_nf.onnx\"\n",
    "net = load_onnx.Onnx_session(model_path,input_mean=0.0, input_std=1.0,onnx_device='cuda')\n",
    "\n",
    "aimg = (ori_img/255. - 0.5)/0.5\n",
    "output = net(aimg)[0]\n",
    "\n",
    "idx = np.argsort(output)[0,::-1][0]\n",
    "p = output[0][idx]\n",
    "pred_name = label_dict[idx]\n",
    "\n",
    "print(pred_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian\n"
     ]
    }
   ],
   "source": [
    "# trt\n",
    "model_path = \"race-mbf-arcface-sgd_221209_nf.v7.trt\"\n",
    "net = load_tensorRT.TrtModel(model_path)\n",
    "\n",
    "output = net(ori_img)[0]\n",
    "idx = np.argsort(output)[0,::-1][0]\n",
    "p = output[0][idx]\n",
    "pred_name = label_dict[idx]\n",
    "\n",
    "print(pred_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian\n"
     ]
    }
   ],
   "source": [
    "# openvino\n",
    "# model_path = [\"race-mbf-arcface-sgd_221209_nf.xml\",\n",
    "#              \"race-mbf-arcface-sgd_221209_nf.bin\"]\n",
    "model_path = [\"race-mbf-arcface-sgd_221209_nf_quantINT8.xml\",\n",
    "             \"race-mbf-arcface-sgd_221209_nf_quantINT8.bin\"]\n",
    "net = load_openvino.Openvino(model_path,device='CPU')\n",
    "\n",
    "output = net(ori_img)[0]\n",
    "idx = np.argsort(output)[0,::-1][0]\n",
    "p = output[0][idx]\n",
    "pred_name = label_dict[idx]\n",
    "\n",
    "print(pred_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
