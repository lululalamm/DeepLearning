{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0405c8e1-8776-4995-b7ec-6041af753aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from totalface.model_zoo.model_common import load_onnx,load_tensorRT,load_openvino\n",
    "from totalface.data import read_image\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc3d75d-c1b4-4d5c-a27d-a0150451b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(rgb_img,mean_list=[0.485, 0.456, 0.406],std_list=[0.229, 0.224, 0.225]):\n",
    "    MEAN = 255 * np.array(mean_list)\n",
    "    STD = 255 * np.array(std_list)\n",
    "    rgb_img = rgb_img.transpose(-1, 0, 1)\n",
    "    norm_img = (rgb_img - MEAN[:, None, None]) / STD[:, None, None]\n",
    "    \n",
    "    return norm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f89effda-7521-4cb1-8cbb-c884839249b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providers: ['CUDAExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "# onnx (norm, numpy array, (H,W,C))\n",
    "lb_num=5\n",
    "input_size=112\n",
    "model_type='onnx'\n",
    "model_path = \"./dan_230503_e34.onnx\"\n",
    "model = load_onnx.Onnx_session(model_path,input_mean=0.0, input_std=1.0,output_sort=True,onnx_device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84b789-0593-4278-9c69-fb19f1ec49e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorRT (norm, torch tensor, (N,C,H,W)\n",
    "lb_num=5\n",
    "input_size=112\n",
    "model_type='trt'\n",
    "model_path = \"dan_230503_e34.v8.trt\"\n",
    "model = load_tensorRT.TrtModel(model_path,torch_image=True,not_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d274adff-6acf-4ee7-8084-1986a517b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openvino (norm, torch tensor, (N,C,H,W)\n",
    "lb_num=5\n",
    "input_size=112\n",
    "model_type='openvino'\n",
    "model_path = [\"dan_230503_e34.xml\", \\\n",
    "              \"dan_230503_e34.bin\"]\n",
    "model = load_openvino.Openvino(model_path,not_norm=True,torch_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50a4fced-a32c-4bb5-bb77-848f2f402f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lb_num==5:\n",
    "    exp_cls = ['happy','surprise','anger','sorrow','neurality']\n",
    "elif lb_num==7:\n",
    "    exp_cls = [\"happy\",\"embarrassed\",\"anger\",\"anxious\",\"hurt\",\"sorrow\",\"neutrality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc4f5a06-7c37-4759-94c3-26ca364792fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94ce39ed-19a3-4687-b115-66f83fed11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./test_aimg.jpg\" # aligned image\n",
    "img = read_image(img_path)\n",
    "img = cv2.resize(img,(input_size,input_size))\n",
    "norm_aimg = normalization(img)\n",
    "if model_type=='onnx':\n",
    "    norm_aimg = norm_aimg.transpose(1,2,0) # (3,size,size) -> (size,size,3) \n",
    "else:\n",
    "    norm_aimg = torch.from_numpy(norm_aimg).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d46d55ca-3345-4a55-a402-f6f27677883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,out = model(norm_aimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78e75fc9-898f-4f96-95d2-8fcce031cbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(out)\n",
    "pred = exp_cls[pred]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42bc9019-53a1-498b-8b24-4e8695f4fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e54f925b-0ec5-4285-9bc6-6e520619ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sf = softmax(out)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "411b2c9c-b10d-42ad-ae1d-da560e046144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3142078e-04, 6.8300980e-01, 1.0039210e-03, 3.1351376e-01,\n",
       "       1.7487615e-03, 2.3811695e-04, 2.5419690e-04], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c51886-ce6e-4272-8bc0-3efb011fbb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
