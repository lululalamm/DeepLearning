{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325ac5b8-6fc8-4a24-bf72-84a87aa8a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae334f3-3f71-4281-82cf-9b02def0eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427247f8-452a-4ed6-8e02-ff91096c4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(rgb_img,mean_list=[0.485, 0.456, 0.406],std_list=[0.229, 0.224, 0.225]):\n",
    "    MEAN = 255 * np.array(mean_list)\n",
    "    STD = 255 * np.array(std_list)\n",
    "    rgb_img = rgb_img.transpose(-1, 0, 1)\n",
    "    norm_img = (rgb_img - MEAN[:, None, None]) / STD[:, None, None]\n",
    "    \n",
    "    return norm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51fd4253-64c3-478c-95b6-48b50ee01806",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"Safas_wildcelebA_align.pth\"\n",
    "output_path = \"Safas_wildcelebA_align.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f69d4ae-6278-4373-9bde-c8b4d8862de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'ResNet18_lgt'\n",
    "max_iter=-1\n",
    "total_cls_num = 2\n",
    "normfc = False\n",
    "usebias = True\n",
    "feat_loss = 'supcon'\n",
    "\n",
    "model = get_model(model_type, \\\n",
    "                  max_iter, total_cls_num, pretrained=False, \\\n",
    "                  normed_fc=normfc, use_bias=usebias, \\\n",
    "                  simsiam=True if feat_loss == 'simsiam' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22312ef3-c8d6-4d50-9474-d6f2030ba9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(ckpt_path)\n",
    "state_dict = ckpt['state_dict']\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for n, v in state_dict.items():\n",
    "    name = n.replace(\"module.\",\"\") # dataparallel\n",
    "    new_state_dict[name] = v\n",
    "model.load_state_dict(new_state_dict)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "697e4f55-007c-4a61-b353-481e762ef145",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.randint(0, 255, size=(256, 256, 3), dtype=np.uint8)\n",
    "img = normalization(img)\n",
    "img = torch.tensor(np.expand_dims(img,0).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee3af1e2-f0af-4b82-abb2-e60d4d59a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "opset=12\n",
    "torch.onnx.export(model, img, output_path, keep_initializers_as_inputs=False, verbose=False, opset_version=opset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb4a7941-dcab-4ae0-9447-5f32884f0dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">WARNING: The argument `input_shapes` is deprecated. Please use `overwrite_input_shapes` and/or `test_input_shapes` </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">instead. An error will be raised in the future.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mWARNING: The argument `input_shapes` is deprecated. Please use `overwrite_input_shapes` and/or `test_input_shapes` \u001b[0m\n",
       "\u001b[1;31minstead. An error will be raised in the future.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simplify\n",
    "\n",
    "import onnxsim\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(output_path)\n",
    "graph = model.graph\n",
    "graph.input[0].type.tensor_type.shape.dim[0].dim_param = 'None'\n",
    "\n",
    "model, check = onnxsim.simplify(model, input_shapes={\"input.1\":(1, 3, 256, 256)})\n",
    "assert check, \"Simplified ONNX model could not be validated\"\n",
    "onnx.save(model, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bf06b-b51d-40c6-94a9-a3e8e58034e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
